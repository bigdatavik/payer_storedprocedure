{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecb0c737-61bc-4a91-a9da-fb752f899bca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "*Note:** This guide requires **Databricks SQL, Databricks Runtime 17.0 or above**, and Unity Catalog only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b51ab177-7f54-4683-9adf-b73b36fbb8f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Introduction\n",
    "This guide shows how to design a Databricks medallion architecture (bronze, silver, gold) pipeline with SQL, using sample tables and realistic transformations relevant to a **healthcare payer**. All code is written to work in Databricks SQL notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "979a9246-402c-479e-aef6-f29943d5f664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# What is a lakehouse?\n",
    "\n",
    "1. **Hybrid Architecture:**  \n",
    "   A lakehouse combines the best of data lakes (flexible, cheap storage) and data warehouses (structured, fast analytics), providing transactional and governance features on top of open cloud storage.\n",
    "\n",
    "2. **ACID Transactions and Schema Governance:**  \n",
    "   Lakehouses support ACID transactions for consistent concurrent data access and enforce schema management, which is essential for data integrity and compliance.\n",
    "\n",
    "3. **Open and Decoupled:**  \n",
    "   They use open file formats (like Parquet), decouple compute from storage for flexible scalability, and allow access by a variety of analytics, BI, and machine learning tools.\n",
    "\n",
    "4. **Supports All Workloads and Data Types:**  \n",
    "   The architecture enables SQL analytics, data science, machine learning, and can handle structured, semi-structured, and unstructured data (including images, text, video).\n",
    "\n",
    "5. **Single Platform, Enterprise Ready:**  \n",
    "   With features like real-time streaming, end-to-end governance, access control, and data discovery tools, lakehouses reduce complexity—allowing enterprises to manage all data and analytics needs in one unified system.\n",
    "![](https://www.databricks.com/wp-content/uploads/2020/01/data-lakehouse-new.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dc272da-63ab-456c-bec7-9ef87b0cdcc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Unity Catalog\n",
    "\n",
    "[Unified and open governance for data and AI in the Lakehouse](https://www.databricks.com/product/unity-catalog#features)\n",
    "\n",
    "[Demo link UC](https://adb-984752964297111.11.azuredatabricks.net/explore/data/quickstart_catalog_vkm_external?o=984752964297111&filterString=payorayor)\n",
    "\n",
    "[Demo link (Discover Your org's Trusted Data & AI Assets)](https://adb-984752964297111.11.azuredatabricks.net/discover?o=984752964297111)\n",
    "\n",
    "Eliminate silos, simplify governance and accelerate insights at scale\n",
    "\n",
    "- Centralizes governance, access control, auditing, and data discovery for all data and AI assets across Databricks workspaces.\n",
    "- Enables fine-grained, consistent data access policies (row- and column-level), defined once and applied everywhere.\n",
    "- Provides comprehensive data lineage and audit logs, showing how and by whom data is accessed and transformed.\n",
    "- Supports data discovery, tagging, and documentation, making it easier to find and understand datasets and models.\n",
    "- Works across multiple clouds and supports open formats (Delta, Parquet, etc.), avoiding vendor lock-in and enabling broad interoperability.\n",
    "- Allows secure data and AI sharing within and outside the organization, including clean rooms and partner collaborations.\n",
    "- Provides built-in monitoring for data quality, freshness, and usage, helping ensure compliance and rapid troubleshooting.\n",
    "- Integrates tightly with the catalog/schema/object model, enhancing organization and security for all managed data assets.\n",
    "\n",
    "![](https://www.databricks.com/sites/default/files/2025-05/header-unity-catalog.png?v=1748513086)\n",
    "\n",
    "[Unity Catalog Search & Data Explorer](https://app.getreprise.com/launch/96mpAqy/)\n",
    "\n",
    "[Exploring Lineage and Governance with Unity Catalog](https://app.getreprise.com/launch/MnqjQDX/)\n",
    "\n",
    "[A Comprehensive Guide to Data and AI Governance](https://www.databricks.com/sites/default/files/2024-08/comprehensive-guide-to-data-and-ai-governance.pdf)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5571fe0-a829-411d-b1ee-b827fd1b4c3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Medallion lakehouse architecture\n",
    "\n",
    "In this example, we will be following the **medallion lakehouse architecture**. The medallion architecture is a data design pattern to organize data in a lakehouse. The goal is to progressively improve the quality and structure of the data as it flows through each layer (Bronze [**raw**] → Silver [**staging**] → Gold [**main**]).\n",
    "\n",
    "1. **Bronze layer**: the raw, unvalidated data\n",
    "2. **Silver**: cleansed and conformed data\n",
    "3. **Gold**: curated business-level tables\n",
    "\n",
    "<img src=\"https://www.databricks.com/sites/default/files/inline-images/building-data-pipelines-with-delta-lake-120823.png?v=1702318922\" alt=\"Managed Tables\" width=\"600\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8292153-2b0a-47dd-b6c6-b1cf4c45cdba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Managed tables\n",
    "\n",
    "[Demo Link](https://adb-984752964297111.11.azuredatabricks.net/explore/data/quickstart_catalog_vkm_external/payor_bronze/claims_raw?o=984752964297111&activeTab=details)\n",
    "\n",
    "[How Unity Catalog Managed Tables Automate Performance at Scale](https://www.databricks.com/blog/how-unity-catalog-managed-tables-automate-performance-scale) with [Predictive Optimization](https://www.databricks.com/blog/predictive-optimization-automatically-delivers-faster-queries-and-lower-tco)\n",
    "\n",
    "\n",
    "<!-- ![](https://www.databricks.com/sites/default/files/inline-images/image2_48.png?v=1751297384) -->\n",
    "\n",
    "<img src=\"https://www.databricks.com/sites/default/files/inline-images/image2_48.png?v=1751297384\" alt=\"Managed Tables\" width=\"600\" height=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9115bf6-333a-4cb8-965c-5e73a2d204d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[Faster Queries: 20X query latency reduction](https://www.databricks.com/blog/predictive-optimization-automatically-delivers-faster-queries-and-lower-tco)\n",
    "\n",
    "[Demo Link](https://adb-984752964297111.11.azuredatabricks.net/explore/data/quickstart_catalog_vkm_external?o=984752964297111&activeTab=details)\n",
    "\n",
    "**Predictive Optimization** in Databricks automates table management by leveraging Unity Catalog and the Data Intelligence Platform. This innovative feature currently runs the following optimizations for Unity Catalog managed tables:\n",
    "\n",
    "<img src=\"https://www.databricks.com/sites/default/files/styles/max_1000x1000/public/2024-05/db-976-blog-img-og.png?itok=qWBT8VA-&v=1717158571\" alt=\"Managed Tables\" width=\"600\" height=\"500\">\n",
    "\n",
    "**Compaction** - This enhances query performance by optimizing file sizes, ensuring that data retrieval is efficient.\n",
    "\n",
    "**Liquid Clustering** - This technique incrementally clusters incoming data, enabling optimal data layout and efficient data skipping.\n",
    "\n",
    "**VACUUM** - This operation helps reduce costs by deleting unneeded files from storage.\n",
    "\n",
    "**ANALYZE** - Predictive Optimization will intelligently update statistics used to optimize query plans, by running ANALYZE in the background. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ce4ebf7-dc51-44bc-8bf2-804fec60b0a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Medallion Pipeline for a Healthcare Payer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f75be99a-8ae5-4056-8ef9-6d1763695c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Modeling Concepts\n",
    "\n",
    "Databricks fully supports both **dimensional modeling** (Kimball/star schema) and **Inmon-style, Data Vault architectures (hubs, satellites, links)** on the Lakehouse platform. For dimensional models, you can build classic star and snowflake schemas directly with SQL, benefiting from ACID transactions and scalable Delta Lake tables.\n",
    "\n",
    "For Inmon/Data Vault use cases, Databricks provides rich support for hub-and-satellite models that address core enterprise needs for history, auditability, and extensibility—find end.\n",
    "\n",
    "The Lakehouse approach lets you mix these styles as needed within a single platform, so you can incrementally land data in Raw Vault/EDW structures and later expose it as dimensional marts—all with Delta Live Tables, fine-grained security, and open formats.\n",
    "\n",
    "Key blog resources:\n",
    "\n",
    "[Dimensional Modeling](https://www.databricks.com/blog/implementing-dimensional-data-warehouse-databricks-sql-part-1)\n",
    "\n",
    "[Data Vault/Hub-Satellite](https://www.databricks.com/blog/2022/06/24/prescriptive-guidance-for-implementing-a-data-vault-model-on-the-databricks-lakehouse-platform.html) \n",
    "\n",
    "[Data Vault best practices](https://www.databricks.com/blog/data-vault-best-practice-implementation-lakehouse)\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between;\">\n",
    "  <img src=\"https://user-gen-media-assets.s3.amazonaws.com/gpt4o_images/5c87faea-3e60-4f71-826d-42d04f6cdc0b.png\" alt=\"Managed Tables\" width=\"400\" height=\"350\">\n",
    "  <img src=\"https://user-gen-media-assets.s3.amazonaws.com/gpt4o_images/6826c275-d462-4c07-a978-43fe9c40f3ed.png\" alt=\"Managed Tables\" width=\"400\" height=\"350\">\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33043442-a66b-47f2-9f2c-c6890d2de349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sample Data Model\n",
    "\n",
    "For a payer, commonly used tables include:\n",
    "\n",
    "- **Members**: members enrolled in a health plan\n",
    "\n",
    "- **Claims**: medical claim submissions\n",
    "\n",
    "- **Providers**: healthcare providers (doctors, clinics)\n",
    "\n",
    "- **Diagnoses**: claim diagnosis codes\n",
    "\n",
    "- **Procedures**: procedures/services performed\n",
    "\n",
    "Each table should have at least 50 rows.\n",
    "\n",
    "<img src=\"https://user-gen-media-assets.s3.amazonaws.com/gpt4o_images/bdd54dc0-f3c7-4975-80a3-0017ebdb121c.png\" alt=\"Managed Tables\" width=\"400\" height=\"300\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5bd63ca-5638-422f-a991-0d6c3d37a2da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Table\tKey Columns\n",
    "\n",
    "**Members**\tmember_id, first_name, last_name, birth_date, gender, plan_id, effective_date\n",
    "\n",
    "**Claims**\tclaim_id, member_id, provider_id, claim_date, total_charge, claim_status\n",
    "\n",
    "**Providers**\tprovider_id, npi, provider_name, specialty, address, city, state\n",
    "\n",
    "**Diagnoses**\tclaim_id, diagnosis_code, diagnosis_desc\n",
    "\n",
    "**Procedures**\tclaim_id, procedure_code, procedure_desc, amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bafefc29-7bfa-4d5a-ac12-de109b0f1961",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50bd3a4c-0f62-4864-975f-69501619f07c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog\", \"quickstart_catalog_vkm_external\", \"Catalog\")\n",
    "dbutils.widgets.text(\"bronze_db\", \"payor_bronze\", \"Bronze DB\")\n",
    "dbutils.widgets.text(\"silver_db\", \"payor_silver\", \"Silver DB\")\n",
    "dbutils.widgets.text(\"gold_db\", \"payor_gold\", \"Gold DB\")\n",
    "\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "bronze_db = dbutils.widgets.get(\"bronze_db\")\n",
    "silver_db = dbutils.widgets.get(\"silver_db\")\n",
    "gold_db = dbutils.widgets.get(\"gold_db\")\n",
    "\n",
    "path = f\"/Volumes/{catalog}/{bronze_db}/payor/files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "592eef4e-3248-4561-8fd7-c4ba3ec8124f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Catalog: {catalog}\")\n",
    "print(f\"Bronze DB: {bronze_db}\")\n",
    "print(f\"Silver DB: {silver_db}\")\n",
    "print(f\"Gold DB: {gold_db}\")\n",
    "print(f\"Path: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "266b9385-33f7-487c-898d-50a28495e752",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Catalog"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8747d067-1569-4679-a336-41dcc5479627",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Catalog and Create ALL Schema"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"USE CATALOG {catalog}\")\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {bronze_db}\")\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {silver_db}\")\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {gold_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18eb9f1f-6739-42d1-9d35-d1dd189351f2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Volume"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {bronze_db}.payor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f80de25-96fb-4816-8db1-2dc3cb7bc670",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Directories and upload files manually"
    }
   },
   "outputs": [],
   "source": [
    "# Create the volume and folders\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{catalog}/{bronze_db}/payor/files/claims\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{catalog}/{bronze_db}/payor/files/diagnosis\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{catalog}/{bronze_db}/payor/files/procedures\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{catalog}/{bronze_db}/payor/files/members\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{catalog}/{bronze_db}/payor/files/providers\")\n",
    "dbutils.fs.mkdirs(f\"/Volumes/{catalog}/{bronze_db}/payor/downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97733cb8-8ede-4fef-a426-1b080b605330",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the URL of the ZIP file\n",
    "# url = \"https://github.com/bigdatavik/notebookassets/blob/6ca9ed60c60e37b6e98d90cb7817746e7880e170/common/Payor_Archive.zip?raw=true\"\n",
    "\n",
    "url = \"https://github.com/bigdatavik/databricksfirststeps/blob/6b225621c3c010a2734ab604efd79c15ec6c71b8/data/Payor_Archive.zip?raw=true\"\n",
    "\n",
    "\n",
    "# Download the ZIP file\n",
    "response = requests.get(url)\n",
    "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "# Define the base path\n",
    "base_path = f\"/Volumes/{catalog}/{bronze_db}/payor/downloads\" \n",
    "\n",
    "# Extract the ZIP file to the base path\n",
    "zip_file.extractall(base_path)\n",
    "\n",
    "# Define the paths\n",
    "paths = {\n",
    "    \"claims.csv\": f\"{base_path}/claims\",\n",
    "    \"diagnoses.csv\": f\"{base_path}/diagnosis\",\n",
    "    \"procedures.csv\": f\"{base_path}/procedures\",\n",
    "    \"member.csv\": f\"{base_path}/members\",\n",
    "    \"providers.csv\": f\"{base_path}/providers\"\n",
    "}\n",
    "\n",
    "# Create the destination directories if they do not exist\n",
    "for dest_path in paths.values():\n",
    "    os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "# Move the files to the respective directories\n",
    "for file_name, dest_path in paths.items():\n",
    "    source_file = f\"{base_path}/{file_name}\"\n",
    "    if os.path.exists(source_file):\n",
    "        os.rename(source_file, f\"{dest_path}/{file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "452ac165-78d6-4aa4-899c-e359b121fff1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Copy the files to the specified directories and print the paths\n",
    "shutil.copy(f\"{base_path}/claims/claims.csv\", f\"/Volumes/{catalog}/{bronze_db}/payor/files/claims/claims.csv\")\n",
    "print(f\"Copied to /Volumes/{catalog}/{bronze_db}/payor/files/claims/claims.csv\")\n",
    "\n",
    "shutil.copy(f\"{base_path}/diagnosis/diagnoses.csv\", f\"/Volumes/{catalog}/{bronze_db}/payor/files/diagnosis/diagnosis.csv\")\n",
    "print(f\"Copied to /Volumes/{catalog}/{bronze_db}/payor/files/diagnosis/diagnosis.csv\")\n",
    "\n",
    "shutil.copy(f\"{base_path}/procedures/procedures.csv\", f\"/Volumes/{catalog}/{bronze_db}/payor/files/procedures/procedures.csv\")\n",
    "print(f\"Copied to /Volumes/{catalog}/{bronze_db}/payor/files/procedures/procedures.csv\")\n",
    "\n",
    "shutil.copy(f\"{base_path}/members/member.csv\", f\"/Volumes/{catalog}/{bronze_db}/payor/files/members/members.csv\")\n",
    "print(f\"Copied to /Volumes/{catalog}/{bronze_db}/payor/files/members/members.csv\")\n",
    "\n",
    "shutil.copy(f\"{base_path}/providers/providers.csv\", f\"/Volumes/{catalog}/{bronze_db}/payor/files/providers/providers.csv\")\n",
    "print(f\"Copied to /Volumes/{catalog}/{bronze_db}/payor/files/providers/providers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dfe9c8c-62f9-4cc5-93ad-4de0a734d392",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[Upload files](https://github.com/bigdatavik/notebookassets/blob/6ca9ed60c60e37b6e98d90cb7817746e7880e170/common/Payor_Archive.zip) to your Volumes or directly to ADLS on Azure, e.g.:\n",
    "\n",
    "members.csv\n",
    "\n",
    "claims.csv\n",
    "\n",
    "providers.csv\n",
    "\n",
    "diagnoses.csv\n",
    "\n",
    "procedures.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "209c8fdf-7b40-41fb-87a2-3b7ae5835233",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bronze Layer – Ingest Raw Data\n",
    "\n",
    "The bronze layer ingests raw files (CSV, JSON, Parquet) and lands them in Delta tables with minimal transformation.\n",
    "\n",
    "**Example: Create Bronze Tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "242023e4-0a88-4c9c-8da6-04d5088dc662",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "List Files in Payor Claims Directory (Testing)"
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# LIST '/Volumes/quickstart_catalog_vkm_external/payor_bronze/payor/files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ee0a970-02b6-4be4-8675-d0219d62d335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## COPY INTO\n",
    "\n",
    "[COPY INTO](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/delta-copy-into) Loads data from a file location into a Delta table. This is a retryable and idempotent operation — Files in the source location that have already been loaded are skipped.\n",
    "\n",
    "[Examples](https://learn.microsoft.com/en-us/azure/databricks/ingestion/cloud-object-storage/copy-into/)\n",
    "\n",
    "[Tutorial](https://learn.microsoft.com/en-us/azure/databricks/ingestion/cloud-object-storage/copy-into/tutorial-notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de08d113-46e5-4786-a596-ad41d2ec1e14",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Claims Data into Bronze Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {bronze_db}.claims_raw (\n",
    "    claim_id STRING,\n",
    "    member_id STRING,\n",
    "    provider_id STRING,\n",
    "    claim_date STRING,\n",
    "    total_charge STRING,\n",
    "    claim_status STRING\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0244b1d5-fa99-4c50-ba55-1df54edb3ecc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "copy_into_query = f\"\"\"\n",
    "COPY INTO {bronze_db}.claims_raw\n",
    "FROM '{path}/claims/'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS (\n",
    "    'header' = 'true'\n",
    ")\n",
    "\"\"\"\n",
    "spark.sql(copy_into_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "667ca891-f9f2-4750-bf0d-80b08c731289",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Diagnosis Data into Bronze Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {bronze_db}.diagnosis_raw (\n",
    "    claim_id STRING,\n",
    "    diagnosis_code STRING,\n",
    "    diagnosis_desc STRING\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "421a5a59-71f1-41e6-90a5-4abfa47a0eec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "copy_into_diag = f\"\"\"\n",
    "COPY INTO {bronze_db}.diagnosis_raw\n",
    "FROM '{path}/diagnosis/'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS (\n",
    "    'header' = 'true'\n",
    ")\n",
    "\"\"\"\n",
    "spark.sql(copy_into_diag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea5d131e-64d6-4806-b211-bda55671d1ac",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Members Data into Bronze Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {bronze_db}.members_raw (\n",
    "    member_id STRING,\n",
    "    first_name STRING,\n",
    "    last_name STRING,\n",
    "    birth_date STRING,\n",
    "    gender STRING,\n",
    "    plan_id STRING,\n",
    "    effective_date STRING\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6818d8f3-0ade-44b1-9050-01cc38dfd4e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "copy_into_members = f\"\"\"\n",
    "COPY INTO {bronze_db}.members_raw\n",
    "FROM '{path}/members'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS (\n",
    "    'header' = 'true'\n",
    ")\n",
    "\"\"\"\n",
    "spark.sql(copy_into_members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a88885f-ecbb-4784-adb6-3be6a2a52957",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Procedures Data into Bronze Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {bronze_db}.procedures_raw (\n",
    "    claim_id STRING,\n",
    "    procedure_code STRING,\n",
    "    procedure_desc STRING,\n",
    "    amount STRING\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3848f4c-f81a-45ff-916d-dc530131aee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "copy_into_procedures = f\"\"\"\n",
    "COPY INTO {bronze_db}.procedures_raw\n",
    "FROM '{path}/procedures'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS (\n",
    "    'header' = 'true'\n",
    ")\n",
    "\"\"\"\n",
    "spark.sql(copy_into_procedures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "202852d0-199d-4029-83cc-c31e4cb40bc6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load Providers Data into Bronze Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {bronze_db}.providers_raw (\n",
    "    provider_id STRING,\n",
    "    npi STRING,\n",
    "    provider_name STRING,\n",
    "    specialty STRING,\n",
    "    address STRING,\n",
    "    city STRING,\n",
    "    state STRING\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3a0f2ab-f21d-46ba-bd4a-b3de3956dc66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "copy_into_providers = f\"\"\"\n",
    "COPY INTO {bronze_db}.providers_raw\n",
    "FROM '{path}/providers'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS (\n",
    "    'header' = 'true'\n",
    ")\n",
    "\"\"\"\n",
    "spark.sql(copy_into_providers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb123759-ef4a-4c75-ae91-9ce33afe32ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver Layer – Transform, Clean, and Join\n",
    "\n",
    "The silver layer cleans data, applies business rules, type-casts fields, deduplicates, and joins tables when needed.\n",
    "\n",
    "**Example: Transform Bronze to Silver**\n",
    "\n",
    "Create Silver Schema and Deduplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ba9220a-c5d1-4578-828b-6f1907e6dece",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create ETL Log Table"
    }
   },
   "outputs": [],
   "source": [
    "# Create ETL log table\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {silver_db}.etl_log (\n",
    "  etl_timestamp TIMESTAMP,\n",
    "  operation STRING,\n",
    "  details STRING\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1fa7e64-1722-49f3-800a-024e5302c13c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Procedure to Transform Members Data with ETL Log"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE PROCEDURE {silver_db}.sprocs_transform_members()\n",
    "LANGUAGE SQL\n",
    "SQL SECURITY INVOKER\n",
    "AS\n",
    "BEGIN\n",
    "    DECLARE run_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP();\n",
    "    CREATE OR REPLACE TABLE {silver_db}.members AS\n",
    "    SELECT DISTINCT\n",
    "        CAST(member_id AS STRING) AS member_id,\n",
    "        TRIM(first_name) AS first_name,\n",
    "        TRIM(last_name) AS last_name,\n",
    "        CAST(birth_date AS DATE) AS birth_date,\n",
    "        gender,\n",
    "        plan_id,\n",
    "        CAST(effective_date AS DATE) AS effective_date\n",
    "    FROM {bronze_db}.members_raw\n",
    "    WHERE member_id IS NOT NULL;\n",
    "\n",
    "     -- Log the ETL operation\n",
    "    INSERT INTO {silver_db}.etl_log (etl_timestamp, operation, details)\n",
    "    VALUES (\n",
    "        run_timestamp,\n",
    "        'sprocs_transform_members_with_log',\n",
    "        'Loaded members from bronze to silver'\n",
    "    );\n",
    "END\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cefcaa38-7f32-4700-8574-2704b5731d51",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Call Procedure to Transform Members"
    }
   },
   "outputs": [],
   "source": [
    "# Command to call the procedure\n",
    "spark.sql(f\"CALL {silver_db}.sprocs_transform_members()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b85372f0-8730-401a-8289-3f0af073bcaa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Procedure for Cleaning Claims Data"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE PROCEDURE {silver_db}.create_clean_claims_table()\n",
    "LANGUAGE SQL\n",
    "SQL SECURITY INVOKER\n",
    "AS\n",
    "BEGIN\n",
    "  DECLARE run_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP();\n",
    "  CREATE OR REPLACE TABLE {silver_db}.claims AS\n",
    "  SELECT DISTINCT\n",
    "    claim_id,\n",
    "    member_id,\n",
    "    provider_id,\n",
    "    CAST(claim_date AS DATE) AS claim_date,\n",
    "    ROUND(try_cast(total_charge AS DECIMAL(10, 2)), 2) AS total_charge,\n",
    "    LOWER(claim_status) AS claim_status\n",
    "  FROM {bronze_db}.claims_raw\n",
    "  WHERE claim_id IS NOT NULL AND try_cast(total_charge AS DECIMAL(10, 2)) IS NOT NULL;\n",
    "\n",
    "  -- Log the ETL operation\n",
    "INSERT INTO {silver_db}.etl_log (etl_timestamp, operation, details)\n",
    "VALUES (\n",
    "    CURRENT_TIMESTAMP(),\n",
    "    'create_clean_claims_table',\n",
    "    'Loaded claims from bronze to silver with valid charges'\n",
    ");\n",
    "END;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3599d49d-e3fe-42f9-9823-b4f02377c1ac",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Call Procedure to Clean Claims Data"
    }
   },
   "outputs": [],
   "source": [
    "# Command to call the procedure\n",
    "spark.sql(f\"CALL {silver_db}.create_clean_claims_table()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ae8edc2-5520-4ada-8c06-b06b34e2e566",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Procedure for Providers Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE PROCEDURE {silver_db}.create_providers_table()\n",
    "LANGUAGE SQL\n",
    "SQL SECURITY INVOKER\n",
    "AS\n",
    "BEGIN\n",
    "  DECLARE run_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP();\n",
    "  \n",
    "  CREATE OR REPLACE TABLE {silver_db}.providers AS\n",
    "  SELECT DISTINCT\n",
    "    provider_id,\n",
    "    npi,\n",
    "    provider_name,\n",
    "    specialty,\n",
    "    address,\n",
    "    city,\n",
    "    state\n",
    "  FROM {bronze_db}.providers_raw\n",
    "  WHERE provider_id IS NOT NULL;\n",
    "\n",
    "  -- Log the ETL operation for providers\n",
    "  INSERT INTO {silver_db}.etl_log (etl_timestamp, operation, details)\n",
    "  VALUES (\n",
    "    CURRENT_TIMESTAMP(),\n",
    "    'create_providers_table',\n",
    "    'Loaded distinct providers from bronze to silver'\n",
    "  );\n",
    "\n",
    "END;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60db3e02-6c4b-4be5-b03e-8e7008b20dd2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Call Procedure to Create Providers Table"
    }
   },
   "outputs": [],
   "source": [
    "# Command to call the procedure\n",
    "spark.sql(f\"CALL {silver_db}.create_providers_table()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4834720-d810-40d4-94df-e657f27a44a3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Procedure for Procedures Table Transformation"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE PROCEDURE {silver_db}.create_procedures_table()\n",
    "LANGUAGE SQL\n",
    "SQL SECURITY INVOKER\n",
    "AS\n",
    "BEGIN\n",
    "  DECLARE run_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP();\n",
    "  CREATE OR REPLACE TABLE {silver_db}.procedures AS\n",
    "  SELECT DISTINCT\n",
    "    claim_id,\n",
    "    UPPER(procedure_code) AS procedure_code,\n",
    "    procedure_desc,\n",
    "    CAST(REPLACE(amount, '$', '') AS DOUBLE) AS amount\n",
    "  FROM {bronze_db}.procedures_raw\n",
    "  WHERE claim_id IS NOT NULL AND procedure_code IS NOT NULL;\n",
    "\n",
    "-- Log the ETL operation for procedures\n",
    "INSERT INTO {silver_db}.etl_log (etl_timestamp, operation, details)\n",
    "VALUES (\n",
    "    CURRENT_TIMESTAMP(),\n",
    "    'create_procedures_table',\n",
    "    'Loaded distinct procedures from bronze to silver'\n",
    ");\n",
    "\n",
    "END;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac68ad8f-cffe-4e3d-b780-e1d2ae004d62",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Call Procedure to Create Transformed Procedures Table"
    }
   },
   "outputs": [],
   "source": [
    "# Command to call the procedure\n",
    "spark.sql(f\"CALL {silver_db}.create_procedures_table()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8771d9f-ca05-4340-8e03-2841d6de37d7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Procedure for Transforming Diagnoses Table"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE PROCEDURE {silver_db}.transform_diagnoses()\n",
    "LANGUAGE SQL\n",
    "SQL SECURITY INVOKER\n",
    "AS\n",
    "BEGIN\n",
    "  DECLARE run_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP();\n",
    "  CREATE OR REPLACE TABLE {silver_db}.diagnoses\n",
    "  SELECT DISTINCT\n",
    "    claim_id,\n",
    "    UPPER(diagnosis_code) AS diagnosis_code,\n",
    "    TRIM(diagnosis_desc) AS diagnosis_desc\n",
    "  FROM {bronze_db}.diagnosis_raw\n",
    "  WHERE claim_id IS NOT NULL AND diagnosis_code IS NOT NULL;\n",
    "\n",
    "-- Log the ETL operation for diagnoses\n",
    "INSERT INTO {silver_db}.etl_log (etl_timestamp, operation, details)\n",
    "VALUES (\n",
    "    CURRENT_TIMESTAMP(),\n",
    "    'transform_diagnoses',\n",
    "    'Loaded distinct diagnoses from bronze to silver'\n",
    ");\n",
    "\n",
    "END;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdcac77c-1548-4d20-87f7-f46b9ab6f29e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Call Procedure to Execute Diagnoses Transformation"
    }
   },
   "outputs": [],
   "source": [
    "# Command to call the procedure\n",
    "spark.sql(f\"CALL {silver_db}.transform_diagnoses()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c91106e3-b2d1-4a46-bdec-ce066badb1d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Gold Layer – Aggregate, Model, Ready for Analytics\n",
    "\n",
    "Gold tables are optimized for business usage: facts, dimensions, and aggregated views.\n",
    "\n",
    "**Example: Build Analytics-Friendly Gold Tables**\n",
    "\n",
    "Create Enriched Claims and Member Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fae190f9-99cf-4b43-a017-9478c225ab06",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create ETL Log Table"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Create ETL log table in gold schema\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {gold_db}.etl_log (\n",
    "  etl_timestamp TIMESTAMP,\n",
    "  operation STRING,\n",
    "  details STRING\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f527d323-8c1e-47c5-a5e8-965071186674",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Procedure for Claims Enrichment with Member, Provider and Diagnosis Data"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE PROCEDURE {gold_db}.enrich_claims()\n",
    "LANGUAGE SQL\n",
    "SQL SECURITY INVOKER\n",
    "AS\n",
    "BEGIN\n",
    "  DECLARE run_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP();\n",
    "  CREATE OR REPLACE TABLE {gold_db}.claims_enriched AS\n",
    "  SELECT\n",
    "    c.claim_id,\n",
    "    c.claim_date,\n",
    "    c.total_charge,\n",
    "    c.claim_status,\n",
    "    m.member_id,\n",
    "    m.first_name,\n",
    "    m.last_name,\n",
    "    m.gender,\n",
    "    m.plan_id,\n",
    "    p.provider_id,\n",
    "    p.provider_name,\n",
    "    p.specialty,\n",
    "    p.city,\n",
    "    p.state,\n",
    "    d.diagnosis_code,\n",
    "    d.diagnosis_desc\n",
    "  FROM {silver_db}.claims c\n",
    "  INNER JOIN {silver_db}.members m ON c.member_id = m.member_id\n",
    "  INNER JOIN {silver_db}.providers p ON c.provider_id = p.provider_id\n",
    "  LEFT JOIN {silver_db}.diagnoses d ON c.claim_id = d.claim_id;\n",
    "\n",
    "-- ETL log insert for enrich_claims operation\n",
    "\n",
    "INSERT INTO {gold_db}.etl_log (etl_timestamp, operation, details)\n",
    "VALUES (\n",
    "    CURRENT_TIMESTAMP(),\n",
    "    'enrich_claims',\n",
    "    'Loaded claims enrichment table in gold schema'\n",
    ");\n",
    "  \n",
    "END;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a179a68-d5cf-4733-8f00-c9a3c65cdb52",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Call Procedure to Update Enrich Claims Data Call"
    }
   },
   "outputs": [],
   "source": [
    "# Command to call the procedure\n",
    "spark.sql(f\"CALL {gold_db}.enrich_claims()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c455d059-46d8-494b-96e2-452feba72a4a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Procedure for Member Claim Summary"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Stored procedure to create member claim summary, with parameterized schemas\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE PROCEDURE {gold_db}.create_member_claim_summary()\n",
    "LANGUAGE SQL\n",
    "SQL SECURITY INVOKER\n",
    "AS\n",
    "BEGIN\n",
    "  CREATE OR REPLACE TABLE {gold_db}.member_claim_summary AS\n",
    "  SELECT\n",
    "    member_id,\n",
    "    COUNT(DISTINCT claim_id) AS total_claims,\n",
    "    SUM(total_charge) AS sum_claims,\n",
    "    MAX(total_charge) AS max_claim,\n",
    "    MIN(total_charge) AS min_claim\n",
    "  FROM {silver_db}.claims\n",
    "  GROUP BY member_id;\n",
    "\n",
    "  INSERT INTO {gold_db}.etl_log (etl_timestamp, operation, details)\n",
    "VALUES (\n",
    "    CURRENT_TIMESTAMP(),\n",
    "    'create_member_claim_summary',\n",
    "    'Loaded member claim summary table in gold schema'\n",
    ");\n",
    "END;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa381267-4a4c-45f9-bb2b-8110c2661a14",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Call Member Claim Summary Procedure"
    }
   },
   "outputs": [],
   "source": [
    "# Command to call the procedure\n",
    "spark.sql(f\"CALL {gold_db}.create_member_claim_summary()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55eeef7f-0571-40ba-9269-87c1388958c3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Sum of Total Charges by Claim Status"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(f\"{gold_db}.claims_enriched\")\n",
    "result = df.groupBy(\"claim_status\").sum(\"total_charge\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ceafe698-1cf6-4ac2-a050-21dd5c0612b9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Sum of Total Charges by Claim Status SparkSQL"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT claim_status, SUM(total_charge) AS total_charge_sum\n",
    "    FROM {gold_db}.claims_enriched\n",
    "    GROUP BY claim_status\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a772eaa0-abc2-43a6-8185-6bbcb61ba3d9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Count of Claims Grouped by Gender"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGYgPSBzcGFyay50YWJsZShmIntnb2xkX2RifS5jbGFpbXNfZW5yaWNoZWQiKQpyZXN1bHQgPSBkZi5ncm91cEJ5KCJnZW5kZXIiKS5jb3VudCgpCmRpc3BsYXkocmVzdWx0KQ==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView9b88a29\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView9b88a29\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView9b88a29\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView9b88a29) SELECT `gender`,SUM(`count`) `column_3c6cda842478` FROM q GROUP BY `gender`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView9b88a29\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Horizontal Chart",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "gender",
             "id": "column_3c6cda842477"
            },
            "y": [
             {
              "column": "count",
              "id": "column_3c6cda842478",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_3c6cda842478": {
             "name": "count",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "c7d6472d-90b5-4136-813a-67b5fb01f6b8",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.9189453125,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "gender",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "gender",
           "type": "column"
          },
          {
           "alias": "column_3c6cda842478",
           "args": [
            {
             "column": "count",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "df = spark.table(f\"{gold_db}.claims_enriched\")\n",
    "result = df.groupBy(\"gender\").count()\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d85dff0f-de3d-4084-bff0-4e8d1c11a22f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Sum of Total Charges Grouped by Claim Date"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGlzcGxheShzcGFyay50YWJsZShmIntnb2xkX2RifS5jbGFpbXNfZW5yaWNoZWQiKS5ncm91cEJ5KCJjbGFpbV9kYXRlIikuc3VtKCJ0b3RhbF9jaGFyZ2UiKS5vcmRlckJ5KCJjbGFpbV9kYXRlIikp\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView241c536\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView241c536\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView241c536\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView241c536) SELECT `claim_date`,SUM(`sum(total_charge)`) `column_3c6cda842489` FROM q GROUP BY `claim_date`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView241c536\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Line Chart",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "claim_date",
             "id": "column_3c6cda842488"
            },
            "y": [
             {
              "column": "sum(total_charge)",
              "id": "column_3c6cda842489",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_3c6cda842489": {
             "name": "sum(total_charge)",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "a82fd1a1-168b-4171-b219-ca56315cf563",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 5.9189453125,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "claim_date",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "claim_date",
           "type": "column"
          },
          {
           "alias": "column_3c6cda842489",
           "args": [
            {
             "column": "sum(total_charge)",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.table(f\"{gold_db}.claims_enriched\").groupBy(\"claim_date\").sum(\"total_charge\").orderBy(\"claim_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6923f450-56f2-46da-a356-dbb09b5a5ec1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Group Claims by City and Count"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGlzcGxheShzcGFyay50YWJsZShmIntnb2xkX2RifS5jbGFpbXNfZW5yaWNoZWQiKS5ncm91cEJ5KCJjaXR5IikuY291bnQoKSk=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView237c274\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView237c274\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView237c274\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView237c274) SELECT `city`,SUM(`count`) `column_3c6cda842507` FROM q GROUP BY `city`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView237c274\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Bar Chart",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "city",
             "id": "column_3c6cda842506"
            },
            "y": [
             {
              "column": "count",
              "id": "column_3c6cda842507",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_3c6cda842507": {
             "name": "count",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": true,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "448dac26-5767-4652-830e-d0e81c3424cc",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 6.9189453125,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "city",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "city",
           "type": "column"
          },
          {
           "alias": "column_3c6cda842507",
           "args": [
            {
             "column": "count",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "display(spark.table(f\"{gold_db}.claims_enriched\").groupBy(\"city\").count())",
       "commandTitle": "Map",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHOROPLETH"
         },
         {
          "key": "options",
          "value": {
           "clusteringMode": "e",
           "colors": {
            "background": "#ffffff",
            "borders": "#ffffff",
            "max": "#002FB4",
            "min": "#799CFF",
            "noValue": "#dddddd"
           },
           "keyColumn": "city",
           "legend": {
            "alignText": "right",
            "position": "bottom-left",
            "visible": true
           },
           "mapType": "usa",
           "noValuePlaceholder": "N/A",
           "popup": {
            "enabled": true,
            "template": "Region: <b>{{ @@name }}</b>\n<br>\nValue: <b>{{ @@value }}</b>"
           },
           "steps": 5,
           "targetField": "name",
           "tooltip": {
            "enabled": true,
            "template": "<b>{{ @@name }}</b>: {{ @@value }}"
           },
           "valueColumn": "count",
           "valueFormat": "0,0.00"
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "b62534d2-5c77-4526-bffd-6ac36cb1e5b4",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 7.9189453125,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.table(f\"{gold_db}.claims_enriched\").groupBy(\"city\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94ee3c88-20a6-4788-95b2-7bc433d43534",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Total Charges from Payor Claims Table"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGlzcGxheShzcGFyay50YWJsZShmIntnb2xkX2RifS5jbGFpbXNfZW5yaWNoZWQiKS5zZWxlY3QoInRvdGFsX2NoYXJnZSIpKQ==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView219e55a\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView219e55a\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView219e55a\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView219e55a) ,min_max AS (SELECT `total_charge`,(SELECT MAX(`total_charge`) FROM q) `target_column_max`,(SELECT MIN(`total_charge`) FROM q) `target_column_min` FROM q) ,histogram_meta AS (SELECT `total_charge`,`target_column_min` `min_value`,IF(`target_column_max` = `target_column_min`,`target_column_max` + 1,`target_column_max`) `max_value`,(`target_column_max` - `target_column_min`) / 10 `step` FROM min_max) SELECT IF(ISNULL(`total_charge`),NULL,LEAST(WIDTH_BUCKET(`total_charge`,`min_value`,`max_value`,10),10)) `total_charge_BIN`,FIRST(`min_value` + ((IF(ISNULL(`total_charge`),NULL,LEAST(WIDTH_BUCKET(`total_charge`,`min_value`,`max_value`,10),10)) - 1) * `step`)) `total_charge_BIN_LOWER_BOUND`,FIRST(`step`) `total_charge_BIN_STEP`,COUNT(`total_charge`) `COUNT` FROM histogram_meta GROUP BY `total_charge_BIN`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView219e55a\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Bar Chart",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "total_charge",
             "id": "column_3c6cda842509"
            }
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "histogram",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numBins": 10,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {},
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "5641bb40-65b6-4acd-aafb-5f180b0ec2e7",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 7.9189453125,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "total_charge_BIN",
           "type": "column"
          }
         ],
         "selects": [
          {
           "alias": "total_charge_BIN",
           "args": [
            {
             "column": "total_charge",
             "type": "column"
            },
            {
             "number": 10,
             "type": "number"
            }
           ],
           "function": "BIN",
           "type": "function"
          },
          {
           "alias": "total_charge_BIN_LOWER_BOUND",
           "args": [
            {
             "column": "total_charge",
             "type": "column"
            },
            {
             "number": 10,
             "type": "number"
            }
           ],
           "function": "BIN_LOWER_BOUND",
           "type": "function"
          },
          {
           "alias": "total_charge_BIN_STEP",
           "args": [
            {
             "column": "total_charge",
             "type": "column"
            },
            {
             "number": 10,
             "type": "number"
            }
           ],
           "function": "BIN_STEP",
           "type": "function"
          },
          {
           "alias": "COUNT",
           "args": [
            {
             "column": "total_charge",
             "type": "column"
            }
           ],
           "function": "COUNT",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.table(f\"{gold_db}.claims_enriched\").select(\"total_charge\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6b953e3-6eba-43c5-8157-48245b421e22",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Claim Date and Total Charge from Payor Claims"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGlzcGxheShzcGFyay50YWJsZShmIntnb2xkX2RifS5jbGFpbXNfZW5yaWNoZWQiKS5zZWxlY3QoImNsYWltX2RhdGUiLCAidG90YWxfY2hhcmdlIikp\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView373bcd5\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView373bcd5\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView373bcd5\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView373bcd5) SELECT `claim_date`,`total_charge` FROM q\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView373bcd5\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Scatter Plot",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "claim_date",
             "id": "column_3c6cda842514"
            },
            "y": [
             {
              "column": "total_charge",
              "id": "column_3c6cda842515"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "scatter",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_3c6cda842515": {
             "name": "total_charge",
             "type": "scatter",
             "yAxis": 0
            },
            "total_charge": {
             "name": "total_charge",
             "type": "scatter",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "8e59f8fe-b565-4c7a-aad2-48446055c509",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.45947265625,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "selects": [
          {
           "column": "claim_date",
           "type": "column"
          },
          {
           "column": "total_charge",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGlzcGxheShzcGFyay50YWJsZShmIntnb2xkX2RifS5jbGFpbXNfZW5yaWNoZWQiKS5zZWxlY3QoImNsYWltX2RhdGUiLCAidG90YWxfY2hhcmdlIikp\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewb434107\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewb434107\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewb434107\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewb434107) SELECT `claim_date`,SUM(`total_charge`) `column_3c6cda842511` FROM q GROUP BY `claim_date`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewb434107\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Line Chart",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "claim_date",
             "id": "column_3c6cda842510"
            },
            "y": [
             {
              "column": "total_charge",
              "id": "column_3c6cda842511",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_3c6cda842511": {
             "name": "total_charge",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "093ecb4c-2a74-40a8-9b46-2d675add2207",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8.9189453125,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "claim_date",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "claim_date",
           "type": "column"
          },
          {
           "alias": "column_3c6cda842511",
           "args": [
            {
             "column": "total_charge",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.table(f\"{gold_db}.claims_enriched\").select(\"claim_date\", \"total_charge\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1a066c3-a0c9-41e8-bdd4-475282fb0950",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# AI/BI\n",
    "\n",
    "Intelligent analytics for everyone\n",
    "\n",
    "Databricks AI/BI is a new type of business intelligence product designed to provide a deep understanding of your data's semantics, enabling self-service data analysis for everyone in your organization. AI/BI is built on a compound AI system that draws insights from the full lifecycle of your data across the Databricks platform, including ETL pipelines, lineage, and other queries.\n",
    "\n",
    "<img src=\"https://www.databricks.com/sites/default/files/2025-05/hero-image-ai-bi-v2-2x.png?v=1748417271\" alt=\"Managed Tables\" width=\"600\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42d91f71-49c0-4b12-9bf9-110eac604994",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Payer AI/BI Dashboard\n",
    "\n",
    "[AI/BI Dashboard ](https://adb-984752964297111.11.azuredatabricks.net/dashboardsv3/01f06a2e1390178b9800d808358c49ad/published?o=984752964297111)\n",
    "\n",
    "-- Show how to ask Genie followup questions on Dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa71c33b-47d1-4b46-9940-2fdfd3cfb439",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Genie\n",
    "\n",
    "Talk with your data\n",
    "\n",
    "Now everyone can get insights from data simply by asking questions in natural language.\n",
    "\n",
    "<img src=\"https://www.databricks.com/sites/default/files/2025-06/ai-bi-genie-hero.png?v=1749162682\" alt=\"Managed Tables\" width=\"600\" height=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2cb9c53-012f-479d-85ec-6c252e01b7d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Payer Genie Room\n",
    "[Payer Genie Room](https://adb-984752964297111.11.azuredatabricks.net/genie/rooms/01f06a3068a81406a386e8eaefc74545?o=984752964297111)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5261002272436203,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2,
    "widgetLayout": [
     {
      "breakBefore": false,
      "name": "catalog",
      "width": 192
     },
     {
      "breakBefore": false,
      "name": "bronze_db",
      "width": 192
     },
     {
      "breakBefore": false,
      "name": "silver_db",
      "width": 192
     },
     {
      "breakBefore": false,
      "name": "gold_db",
      "width": 192
     }
    ]
   },
   "notebookName": "payer_medallion_Load_SQL_storedProcedures",
   "widgets": {
    "bronze_db": {
     "currentValue": "payor_bronze3",
     "nuid": "6dfa620d-8496-4272-a14a-e3ee8f45e0fc",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "payor_bronze",
      "label": "Bronze DB",
      "name": "bronze_db",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "payor_bronze",
      "label": "Bronze DB",
      "name": "bronze_db",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "catalog": {
     "currentValue": "quickstart_catalog_vkm_external",
     "nuid": "11e2806d-549d-48e6-b3bc-cf14130ab8a2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "quickstart_catalog_vkm_external",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "quickstart_catalog_vkm_external",
      "label": "Catalog",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "gold_db": {
     "currentValue": "payor_gold3",
     "nuid": "f55170b0-3967-42af-93b2-fc5914973e09",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "payor_gold",
      "label": "Gold DB",
      "name": "gold_db",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "payor_gold",
      "label": "Gold DB",
      "name": "gold_db",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "silver_db": {
     "currentValue": "payor_silver3",
     "nuid": "0573cd6d-ef93-49e4-aca7-cf1b32882b50",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "payor_silver",
      "label": "Silver DB",
      "name": "silver_db",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "payor_silver",
      "label": "Silver DB",
      "name": "silver_db",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
